{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/drive/1FlLpVn217ag8xYOcar_ygOjixxeVPn8A#scrollTo=QP-WtXKCzLx1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Продвинутый уровень понимания линейной регрессии\n",
    "\n",
    "Как понять, насколько хорошо наша модель \"выучилась\" по данным - насколько хорошо она попала в центр облака точек? Давайте введём какую-то меру качества модели - тогда мы сможем говорить, что модель обучается, когда растёт мера качества ( о метриках качества мы поговорим в следующем урове этого модуля), Процесс машинного обучения сводится к тому, чтобы по опыту (обучающей выборке) $D$ подобрать такие коэффициенты линейной регрессии, что мера качества $L$ будет максимальной. Хорошей мерой качества $L$ для задачи регрессии является среднее значение квадрата разности между фактическим значением $y$ и прогнозом $\\hat{y}$ - такая метрика называется *Mean Squared Error* (берём со знаком минус, т.к. при увеличении качества модели метрика должна расти).\n",
    "$$\n",
    "L(\\hat{y}, y) = -\\frac{1}{N}\\sum_{i=1}^{N}\\left(y_i - \\hat{y_i}\\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия относится в задачам обучения с учителем: опыт $D$ (который в ML называют *обучающей выборкой*) в нашем случае - это набор пар $x_i, y_i$ таких, что\n",
    "\n",
    "$$\n",
    "D = \\{(x_i, y_i) \\}_{i=\\overline{1,N}}\n",
    "$$\n",
    "\n",
    "Где $y_i$ - это \"правильный\" ответ (значение переменной $y$) на обучающем примере $x_i$, а $N$ - количество обучающих примеров. В задаче линейной регрессии $y \\in R$, то есть предсказывать нужно  непрерывную величину (в отличие от задачи классификации, где предсказания должны быть дискретными)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый объект $x_i$ является совокупностью признаков $x_i^1,\\ldots, x_i^k$. Размерность признакового пространства может быть разной, т.е. $x_i \\in R^k$, где $k$ может принимать значения от 1 (в задаче прогнозирования роста человека по его весу) до десятков тысяч (например, в задаче анализа текстов). Вот, например, как выглядит регрессия в трёхмерном пространстве\n",
    "\n",
    "![3d_lin_reg](https://248006.selcdn.ru/public/Data-science-4/img/3d_lin_reg.png)\n",
    "\n",
    "В случае многомерной линейной регрессии для $n-1$ измерений нам нужно будет выучить не два коэффициента $a$ и $b$, а $n$ коэффициентов - по одному на каждую координату $x_i$ плюс один коэффициент-свободный член\n",
    "\n",
    "$$\n",
    "L(\\hat{y}, y) = \\frac{1}{N}\\sum_{i=1}^{N}\\left(y_i - \\hat{y_i}\\right)^2 = \\frac{1}{N}\\sum_{i=1}^{N}\\left(y_i -  \\sum_{j=1}^{n}w_jx_i^j\\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой формуле:\n",
    "\n",
    "* $N$ - размер обучающей выборки (собрали информацию по 124 домам: $N=124$)\n",
    "* $i$ - порядковый номер объекта из обучающей выборки\n",
    "* $y_i$ - значение целевого признака (например, стоимость дома или рост человека) у объекта под номером $i$\n",
    "* $\\hat{y}_i$ - значение целевого признака, которое предсказала линейная регрессия\n",
    "\n",
    "Дальше мы расписываем, как предсказание $\\hat{y}_i$ получается по фичам:\n",
    "$$\n",
    "\\hat{y}_i = \\sum_{j=1}^{n}w_jx_i^j\n",
    "$$\n",
    "\n",
    "в этой формуле\n",
    "\n",
    "* $n$ - количество фичей (если по площади дома предсказываем цену, то $n=1$, у нас одна фича \n",
    "* $w_j$ - коэффициент при фиче под номером $j$, который показывает силу влияния этой фици на целевую переменную например $w_1$ $=$ `сила влияния площади дома на его цену`\n",
    "* $x_i^j$ - фича под номером $j$ у объекта под номером $i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Говоря математическим языком, *задача линейной* регрессии заключается в том, чтобы восстановить функцию зависимости $y$ тот $x$ в виде *линейной комбинации* признаков объекта. Сами признаки называются *фичами* (как и в других задачах машинного обучения):\n",
    "$$\n",
    "\\forall x_i: \\hat{y_i} = w_0 + w_1x_i^1 + \\ldots + + w_nx_i^n = \\sum_{j=1}^{n}w_jx_i^j = \\overline{x}_i^T\\overline{w}\n",
    "$$\n",
    "\n",
    "Если перейти от одного объекта обучающей выборки ко всей выборке с множеством объектом, то формулу **MSE** удобно для дальнейших вычислений переписать в т.н. матричной форме (подробнее см. в [статье про линейную регрессию](https://ru.wikipedia.org/wiki/Линейная_регрессия) )\n",
    "$$\n",
    "Q_{\\text{emp}} = \\frac{1}{2N}\\sum_{i=1}^{N}(y_i - \\hat{y_i})^2 = \\frac{1}{2N}\\sum_{i=1}^{N}(y_i - \\overline{x}_i^T\\overline{w})^2 = \\frac{1}{2N}||\\overline{Y}-\\overline{X}^T\\overline{w}||^2 = \\frac{1}{2N}\\left(\\overline{Y}-\\overline{X}^T\\overline{w}\\right)^T\\left(\\overline{Y}-\\overline{X}^T\\overline{w}\\right)\n",
    "$$\n",
    "\n",
    "Такой вид функции потерь называется RSS - *resudal squares sum*, на русский переводится как *остаточная сумма квадратов*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой формуле:\n",
    "\n",
    "* $Y$ - вектор-столбец с истинными значениями целевой переменной $y$ размерности $N \\times 1$, где $N$ - размер обучающей выборки\n",
    "* $X$ - матрица с фичами размерости $N \\times n$, где $N$ - размер обучающей выборки, а $n$ - число фичей\n",
    "* $w$ - вектор коэффициентов линейной регрессии размерности $1 \\times n$, где $n$ - количество фичей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Где $\\hat{y_i}$ - ответ нашего алгоритма машинного обучения $h(x, \\theta)$ на примере $x_i$. Чем больше значение $L$ (т.е. чем ближе оно к нулю, т.к. берём со знаком минус), тем лучше наша модель повторяет опыт $X \\in m \\times n$ - матрицу, где m - количество примеров в обучающей выборке, а $m$ - размерность пространства признаков. $w$ - это вектор параметров модели, который хотим обучить.\n",
    "\n",
    "Значение коэффициентов линейной регрессии $w$, которые будут являться решением нашей задачи, можно найти аналитически:\n",
    "$$\n",
    "\\overline{w} = \\left(X^TX\\right)^{-1}X^T\\overline{y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, как обучить модель линейной регрессии, пользуясь только библиотечными функциями - имеенно их вы будете применять при решении реальных задач на работе\n",
    "\n",
    "Сначала реализуем вспомогательную функцию для печати чисел  питоновского типа *float* в красивом виде без большого количества знаков после запятой: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndprint(a, format_string ='{0:.2f}'):\n",
    "    \"\"\"Функция, которая распечатывает список в красивом виде\"\"\"\n",
    "    return [format_string.format(v,i) for i,v in enumerate(a)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем исходные данные - датасет с ценами на дома в Бостоне. Это стандартный датасет, который используется для демонстрации алгоритмов настолько часто, что включён прямо в исходный код библиотеки sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>500</td>\n",
       "      <td>0.17783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.569</td>\n",
       "      <td>73.5</td>\n",
       "      <td>2.3999</td>\n",
       "      <td>6</td>\n",
       "      <td>391</td>\n",
       "      <td>19.2</td>\n",
       "      <td>395.77</td>\n",
       "      <td>15.10</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>502</td>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>503</td>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>504</td>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>506</td>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID     crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "0      1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1      2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2      4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "3      5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "4      7  0.08829  12.5   7.87     0  0.524  6.012  66.6  5.5605    5  311   \n",
       "..   ...      ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "328  500  0.17783   0.0   9.69     0  0.585  5.569  73.5  2.3999    6  391   \n",
       "329  502  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
       "330  503  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
       "331  504  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
       "332  506  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
       "\n",
       "     ptratio   black  lstat  medv  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       18.7  394.63   2.94  33.4  \n",
       "3       18.7  396.90   5.33  36.2  \n",
       "4       15.2  395.60  12.43  22.9  \n",
       "..       ...     ...    ...   ...  \n",
       "328     19.2  395.77  15.10  17.5  \n",
       "329     21.0  391.99   9.67  22.4  \n",
       "330     21.0  396.90   9.08  20.6  \n",
       "331     21.0  396.90   5.64  23.9  \n",
       "332     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[333 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston_dataset = load_boston()\n",
    "\n",
    "features = boston_dataset.data\n",
    "y = boston_dataset.target\n",
    "\n",
    "print('Матрица Объекты X Фичи  (размерность): %s %s' % features.shape)\n",
    "print('\\nЦелевая переменная y (размерность): %s' % y.shape)\n",
    "\n",
    "\n",
    "# текстовое описание датасета  - распечатать, если интересно print('\\n',boston_dataset.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем работать с датасетом в котором 506 наблюдений. У каждого наблюдения 13 фичей. Таким образом наша модель - это вектор $w$ в котором 13 компонент $w_1,\\ldots,w_n$ - по одному коэффициенту на каждую фичу.\n",
    "\n",
    "Код для аналитического вычисления коэффициентов линейной регрессии по формуле $\\overline{w} = \\left(X^TX\\right)^{-1}X^T\\overline{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "\n",
    "# вычисляем к-ты линейной регрессии\n",
    "w_analytic = inv(\n",
    "    features.T.dot(features)\n",
    ").dot(\n",
    "    features.T\n",
    ").dot(\n",
    "    y\n",
    ")\n",
    "print(\"Аналитически определённые коэффициенты \\n%s\" % ndprint(w_analytic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы проверить, насколько хорошо мы реализовали аналитическое вычисление коэффициентов, воспользуемся готовой библиотечной реализацией. Библиотечная реализация вычисляет коэффициенты не с помощью перемножения матриц (как мы)ю, а с помощью *приближённых* [методов для численного решения](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.lstsq.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# обучаем модель \"из коробки\"\n",
    "reg = LinearRegression().fit(features, y)\n",
    "print(\"Коэффициенты, вычисленные моделью sklearn \\n%s\" % ndprint(reg.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы реализовали обучение модели линейной регрессии на языке Python, причём полученные коэффициенты в целом совпадают с результатами, полученными с помощью класса `sklearn.linear_model.LinearRegression`, который вычисляет коэффициенты приближённо. На практике пользуются именно библиотечной функцией, потому что при наличии большого количества точке и большого количества фичей \"самописная\" реализация будет работать дольше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
